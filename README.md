# Papers that we read

이 레포지토리는 논문 리뷰를 쉽게 찾기 위해 만들어졌습니다.

**파일명에는 특수문자(:, /, 등)가 들어가지 않도록 합니다**

--------------

### Character motivation modeling

- [Modeling Human Motives and Emotions from Personal Narratives Using External Knowledge And Entity Tracking[WWW2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Character_motivation_modeling/Modeling%20Human%20Motives%20and%20Emotions%20from%20Personal%20Narratives%20Using%20External%20Knowledge%20And%20Entity%20Tracking.md)

### Computer Vision

- [AN IMAGE IS WORTH 16X16 WORDS:TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE [ICLR:2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Computer_Vision/ViT.md)

- [BEIT: BERT PRE-TRAINING OF IMAGE TRANSFORMERS [ICLR:2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Computer_Vision/BEIT.md)

### Curriculum Learning in LM

- [Efficient Pre-training of Masked Language Model via Concept-based Curriculum Masking[EMNLP2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Curriculum_Learning_in_LM/CCM.md)

- [Curriculum Learning for Natural Language Understanding[ACL2020]](https://github.com/IamJunhaHwang/Papers/blob/main/Curriculum_Learning_in_LM/CLforNLU.md)

### Dataset & Subset Selection

- [PANDORA Talks: Personality and Demographics on Reddit[NAACL2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Dataset&Subset/PANDORA.md)
  
- [Style is NOT a single variable: Case Studies for Cross-Style Language Understanding[ACL2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Dataset&Subset/Style%20is%20NOT%20a%20single%20variable.md)
- [BERT on a Data Diet: Finding Important Examples by Gradient-Based Pruning[NeurIPS 2022 - workshop]](https://github.com/DAILAB-CBNU/Papers/blob/main/Dataset&Subset/BERT_on_a_Data_Diet.md)

- [Deduplicating Training Data Makes Language Models Better[ACL:2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Dataset&Subset/Deduplicating%20Training%20Data%20Makes%20Language%20Models%20Better.md)

### Efficient_Learning

- [MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases[ICLR 2024]](https://github.com/IamJunhaHwang/Papers/blob/main/Efficient_Learning/MobileLLM.md)

### Embedding

- [Self-Attention with Relative Position Representations[NAACL 2018]](https://github.com/IamJunhaHwang/Papers/blob/main/Embedding/RPE.md)


### General NLP

- [Character-level Convolutional Networks for Text Classification[NIPS:2015]](https://github.com/DAILAB-CBNU/Papers/blob/main/General_NLP/Character-level%20Convolutional%20Networks%20for%20Text%20Classification.md)

- [Convolutional Neural Networks for Sentence Classification[EMNLP:2014]](https://github.com/DAILAB-CBNU/Papers/blob/main/General_NLP/Convolutional%20Neural%20Networks%20for%20Sentence%20Classification.md)

### Instruction Tuning

- [FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS[ICLR 2022]](https://github.com/IamJunhaHwang/Papers/blob/main/Instruction_Tuning/FLAN(Instruction_tuning).md)

### Language Model

- [Improving Language Understanding by Generative Pre-Training[ARXIV:2018]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/Improving%20Language%20Understanding%20by%20Generative%20Pre-Training.md)

- [Improving Language Understanding by Generative Pre-Training(Jun-Ha Hwang reviewed)](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/GPT-1.md)

- [A^2-Nets: Double Attention Networks[NIPS:2018]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/A2-Nets:%20Double%20Attention%20Networks.md)

- [Universal Language Model Fine-tuning for Text Classification[ACL:2018]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/ULMFiT.md)

- [LLaMA: Open and Efficient Foundation Language Models[ARXIV:2023]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/LLaMA.md)

- [Llama 2: Open Foundation and Fine-Tuned Chat Models [arxiv 2023]](https://github.com/IamJunhaHwang/Papers/blob/main/Language_Model/LLAMA2.md)

- [exBERT: Extending Pre-trained Models with Domain-specific Vocabulary Under Constrained Training Resources[EMNLP:2020-FINDINGS]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/exBERT.md)

- [Fine-tune BERT with Sparse Self-Attention Mechanism[EMNLP|IJCNLP:2019]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/Fine-tune%20BERT%20with%20Sparse%20Self-Attention%20Mechanism.md)

- [What Does BERT Look At? An Analysis of BERT's Attention[BlackBoxNLP:2019]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/What%20Does%20BERT%20Look%20At%3F%20An%20Analysis%20of%20BERT's%20Attention.md)

- [KcBERT: 한국어 댓글로 학습한 BERT[제32회 한글 및 한국어 정보처리 학술대회 논문집:2020]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/KcBERT:%20%ED%95%9C%EA%B5%AD%EC%96%B4%20%EB%8C%93%EA%B8%80%EB%A1%9C%20%ED%95%99%EC%8A%B5%ED%95%9C%20BERT.md)

- [Language Models are Unsupervised Multitask Learners[Preprint:2019]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/GPT-2.md)

- [Language Models are Few-Shot Learners [NeurIPS 2020]](https://github.com/IamJunhaHwang/Papers/blob/main/Language_Model/GPT-3.md)

- [Unified Language Model Pre-training for Natural Language Understanding and Generation [NIPS:2019]](https://github.com/DAILAB-CBNU/Papers/blob/main/Language_Model/UniLM.md)

- [LaMDA: Language Models for Dialog Applications[arXiv preprint 2022]](https://github.com/IamJunhaHwang/Papers/blob/main/Language_Model/LaMDA.md)

- [RWKV: Reinventing RNNs for the Transformer Era [EMNLP 2023 - FINDINGS]](https://github.com/IamJunhaHwang/Papers/blob/main/Language_Model/RWKV.md)

- [RLHF: Learning to summarize from human feedback [NeurIPS 2020]](https://github.com/IamJunhaHwang/Papers/blob/main/Language_Model/RLHF.md)

- [SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling [NAACL2024]](https://github.com/IamJunhaHwang/Papers/blob/main/Language_Model/SOLAR.md)

- [THINK BEFORE YOU SPEAK: TRAINING LANGUAGE MODELS WITH PAUSE TOKENS [ICLR 2024]](https://github.com/IamJunhaHwang/Papers/blob/main/Language_Model/pause_transformer.md)

### Machine Translation

- [Attention Is All You Need[NIPS:2017]](https://github.com/DAILAB-CBNU/Papers/blob/main/Machine_Translation/Attention%20Is%20All%20You%20Need.md)

### Multi-Modal

- [Learning Transferable Visual Models From Natural Language Supervision[ICML:2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Multi-Modal/CLIP.md)

- [Honeybee: Locality-enhanced Projector for Multimodal LLM[CVPR 2024]](https://github.com/IamJunhaHwang/Papers/blob/main/Multi-Modal/Honeybee.md)

### Multi-Task Learning

- [An Overview of Multi-Task Learning in Deep Neural Networks[arxiv:2017]](https://github.com/DAILAB-CBNU/Papers/blob/main/Multi-Task_Learning/An%20Overview%20of%20Multi-Task%20Learning%20in%20Deep%20Neural%20Networks.md)

- [Multitask Learning for Emotion and Personality Detection[IEEE TRANSACTION ON AFFECTIVE COMPUTING:2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Multi-Task_Learning/Multitask%20Learning%20for%20Emotion%20and%20Personality%20Detection.md)

- [Recommending What Video to Watch Next: A Multitask Ranking System[RecSys2019]](https://github.com/DAILAB-CBNU/Papers/blob/main/Multi-Task_Learning/Recommending%20What%20Video%20to%20Watch%20Next:%20A%20Multitask%20Ranking%20System.md)

- [Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes [ACL2023-FINDINGS]](https://github.com/IamJunhaHwang/Papers/blob/main/Multi-Task_Learning/Distilling%20Step-by-Step.md)

### Named Entity Recognition

- [텍스트 채우기와 적대 신경망을 이용한 개체명 인식 데이터 확장[정보과학회논문지:2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Named%20Entity%20Recognition/%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%B1%84%EC%9A%B0%EA%B8%B0%EC%99%80%20%EC%A0%81%EB%8C%80%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EA%B0%9C%EC%B2%B4%EB%AA%85%20%EC%9D%B8%EC%8B%9D%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%ED%99%95%EC%9E%A5.md)

### Natural Language Understanding

- [GPT Understands, Too[arxiv:2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Natural_Language_Understanding/GPT%20Understands%2C%20Too.md)

- [사전학습 언어모델 기반 트랜스포머를 활용한 의미유사도기반 자연어이해 의도파악 방법[정보과학회논문지:2020]](https://github.com/DAILAB-CBNU/Papers/blob/main/Natural_Language_Understanding/%EC%82%AC%EC%A0%84%ED%95%99%EC%8A%B5%20%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8%20%EA%B8%B0%EB%B0%98%20%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%EC%9D%98%EB%AF%B8%EC%9C%A0%EC%82%AC%EB%8F%84%EA%B8%B0%EB%B0%98%20%EC%9E%90%EC%97%B0%EC%96%B4%EC%9D%B4%ED%95%B4%20%EC%9D%98%EB%8F%84%ED%8C%8C%EC%95%85%20%EB%B0%A9%EB%B2%95.md)

### Neural Network

- [Deep Learning[Nature:2015]](https://github.com/DAILAB-CBNU/Papers/blob/main/Neural_Network/Deep_Learning.md)

### Personality Generation

- [Evaluating and Inducing Personality in Pre-trained Language Models[NeurIPS 2023]](https://github.com/IamJunhaHwang/Papers/blob/main/Personality_Generation/EvalandInducePersonality.md)

### Personality Prediction

- [Text based personality prediction from multiple social media data sources using pre‑trained language model and model averaging[JBD:2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Personlity_Prediction/Text%20based%20personality%20prediction%20from%20multiple%20social%20media%20data%20sources%20using%20pre%E2%80%91trained%20language%20model%20and%20model%20averaging.md)
- [The Emotion is Not One-hot Encoding: Learning with Grayscale Label for Emotion Recognition in Conversation[INTERSPEECH:2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Personlity_Prediction/The%20Emotion%20is%20Not%20One-hot%20Encoding.md)
- [Fine-grained Sentiment Classification using BERT[AITB:2019]](https://github.com/DAILAB-CBNU/Papers/blob/main/Personlity_Prediction/Fine-grained%20Sentiment%20Classification%20using%20BERT.md)
- [Aspect Level Sentiment Classification with Attention-over-Attention Neural Networks[SBP-BRiMS:2018]](https://github.com/DAILAB-CBNU/Papers/blob/main/Personlity_Prediction/Aspect%20Level%20Sentiment%20Classification%20with%20Attention-over-Attention%20Neural%20Networks.md)
- [You Are What You Talk About: Inducing Evaluative Topics for Personality Analysis[EMNLP2022-FINDINGS]](https://github.com/DAILAB-CBNU/Papers/blob/main/Personlity_Prediction/you%20are%20what%20you%20talk%20about.md)
- [LLM vs Small Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model [AAAI 2024]](https://github.com/IamJunhaHwang/Papers/blob/main/Personlity_Prediction/LLMvsSmallModel.md)

### Prompt Learning

- [Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference[EACL2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Prompt_Learning/PET.md)

- [It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners[NAACL2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Prompt_Learning/PET2.md)

### Question Answering

- [Empowering Language Models with Knowledge Graph Reasoning for Open-Domain Question Answering[EMNLP2022]](https://github.com/IamJunhaHwang/Papers/blob/main/Question_Answering/KGLM.md)

### Red Teaming

- [Gradient-Based Language Model Red Teaming[EACL2024]](https://github.com/IamJunhaHwang/Papers/blob/main/Red_Teaming/GBRT.md)

### Sentiment Analysis

- [Multi-Domain Targeted Sentiment Analysis[NAACL:2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Sentiment_Analysis/Multi-Domain_Targeted_SA.md)

### Text Generation

- [Multiturn dialogue generation by modeling sentence-level and discourse-level contexts[nature scientific report:2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Multiturn%20dialogue%20generation.md)

- [Instance-wise Prompt Tuning for Pretrained Language Models[arxiv:2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Instance-wise%20Prompt%20Tuning%20for%20Pretrained%20Language%20Models.md)

- [Large Pre-trained Language Model의 P-tuning을 이용한 질의 정규화[제33회 한글 및 한국어 정보처리 학술대회 논문집:2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Large%20Pre-trained%20Language%20Model%EC%9D%98%20P-tuning%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%A7%88%EC%9D%98%20%EC%A0%95%EA%B7%9C%ED%99%94.md)

- [A character-Centric Neural Model for Automated Story Generation](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/A%20character-Centric%20Neural%20Model%20for%20Automated%20Story%20Generation.md)

- [Pretrained Language Models for Text Generation: A Survey](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Pretrained%20Language%20Models%20for%20Text%20Generation:%20A%20Survey.md)

- [Dialogue Generation in Character-based Interactive Storytelling](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Dialogue%20Generation%20in%20Character-based%20Interactive%20Storytelling.md)

- [Musical song lyrics generation system using GPT-2 based on character’s MBTI Tendency](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Musical%20song%20lyrics%20generation%20system%20using%20GPT-2%20based%20on%20character%E2%80%99s%20MBTI%20Tendency.md)

- [Perceived or Not Perceived: Film Character Models for Expressive NLG](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Perceived%20or%20Not%20Perceived:%20Film%20Character%20Models%20for%20Expressive%20NLG.md)

- [감성 및 감정 단어 마스킹 기반 BERT와 GPT 파이프라인 방식을 통한 감정 문장 생성](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/%EA%B0%90%EC%84%B1%20%EB%B0%8F%20%EA%B0%90%EC%A0%95%20%EB%8B%A8%EC%96%B4%20%EB%A7%88%EC%8A%A4%ED%82%B9%20%EA%B8%B0%EB%B0%98%20BERT%EC%99%80%20GPT%20%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8%20%EB%B0%A9%EC%8B%9D%EC%9D%84%20%ED%86%B5%ED%95%9C%20%EA%B0%90%EC%A0%95%20%EB%AC%B8%EC%9E%A5%20%EC%83%9D%EC%84%B1.md)

- [Generating Expository Dialogue from Monologue: Motivation, Corpus and Preliminary Rules](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Generating%20Expository%20Dialogue%20from%20Monologue:%20Motivation%2C%20Corpus%20and%20Preliminary%20Rules.md)


### Text Style Transfer

- [Story-level Text Style Transfer: A Proposal[ACL:2020]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Style_Transfer/Story-level%20Text%20Style%20Transfer:%20A%20Proposal.md)

- [Style Transfer from Non-Parallel Text by Cross-Alignment[NIPS:2017]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Style_Transfer/Style%20Transfer%20from%20Non-Parallel%20Text%20by%20Cross-Alignment.md)

- [A Recipe for Arbitrary Text Style Transfer with Large Language Models[ACL:2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Style_Transfer/A%20Recipe%20for%20Arbitrary%20Text%20Style%20Transfer%20with%20Large%20Language%20Models.md)

- [APPDIA: A Discourse-aware Transformer-based Style Transfer Model for Offensive Social Media Conversations[COLING:2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Style_Transfer/APPDIA.md)

- [P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Style_Transfer/P-Tuning:%20Prompt%20Tuning%20Can%20Be%20Comparable%20to%20Fine-tuning%20Across%20Scales%20and%20Tasks.md)

### Tokenization

- [SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing[EMNLP:2018]](https://github.com/DAILAB-CBNU/Papers/blob/main/Tokenization/SentencePiece.md)

- [Neural Machine Translation of Rare Words with Subword Units[ACL:2016]](https://github.com/DAILAB-CBNU/Papers/blob/main/Tokenization/BPE.md)

- [Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates[ACL:2018]](https://github.com/DAILAB-CBNU/Papers/blob/main/Tokenization/Subword%20Regularization.md)
