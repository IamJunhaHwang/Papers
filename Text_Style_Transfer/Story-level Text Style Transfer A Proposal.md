#### 논문 - Story-level Text Style Transfer: A Proposal

- 저자: Yusu Qian
- Acceted by ACL 2020
- [논문 링크](https://aclanthology.org/2020.acl-srw.2.pdf)

-----------------------------------------------------
- **목적**
  - text style transfer는 내용을 어느 정도 보존하면서 input 텍스트의 스타일을 target 스타일로 변경하는 것을 목표 
    - 입력 문장에서 지정된 속성을 대상 속성으로 변경하는 것
    - 예를 들어 핵심 정보를 유지하면서 긍정적인 문장을 부정적인 문장으로 바꾸는 것
  - 첫째. 주요 줄거리를 보존하기 위해 원작의 구조적 표현을 구축하는 방법을 탐구하는데 여기에는 주연과 그들의 연관성이 포함됨
  - 둘째. 검색된 정보 또는 그래프와 대상 스타일이 주어진 스토리를 생성함
-----------------------------------------------------
- **방법**
  - Proposed Methodology
    - 우리의 목표는 원작 스토리를 목표 설정에 맞추는 것임
    - Dataset
      - 제안된 작업에 이상적인 데이터 세트는 다음 요구 사항을 충족해야 함
        - 첫째, 각 말뭉치는 동일한 스타일의 풍부한 양의 텍스트를 가져야 함
        - 둘째, 각 코퍼스의 스타일은 서로 크게 달라야 함
      - 각 말뭉치에서 100 ~ 200 단어 사이의 단락을 선택하고 GraphRel을 사용하여 텍스트에서 그래프를 자동으로 작성함 
      - 다음에 설명하는 각 방법에 대해 서로 다른 교육 데이터를 사용함
        - BERT 기반의 방법은 story corpora를 훈련 데이터로 사용
        - story-realization 방법의 경우 선택된 단락과 해당 추출된 명명된 entity를 훈련 데이터로 사용
        - 그래프 기반의 방법의 경우 GraphRel에 의해 구축된 선택된 단락과 그래프를 훈련 데이터로 사용
      - 이러한 요구사항을 만족 시키기 위해 해리포터 시리즈와 왕좌의 게임 시리즈를 말뭉치로 선택함
        - 해리포터 시리즈는 1,084,170개의 단어로 구성
        - 왕좌의 게임 시리즈는 1,736,054개의 단어로 구성  
  - Models
    - BERT-based Method
      - 이 방법은 Bidirectional Encoder Representations for Transformers(BERT)를 기반으로 함
      - BERT를 fine-tuning하기 위해 target style의 corpus를 사용
      - 그 다음 minimum occurrence를 20으로 설정하여 target corpus에 대한 vocabulary 구축
      - input 스토리의 각 던어가 target corpus의 vocab에 포함되는지 여부를 조사
        - 포함되지 않으면 fine-tuning된 BERT를 사용하여 이러한 단어를 하나씩 마스킹하고 예측
      - 이 기반 방법은 전체가 아닌 문장별로 입력 스토리를 수정하기 대문에 기준 모델 역할을 함
    - story Realization Method
      - plot events가 주어질 때 문장을 생성하는 ensemble-based model(Ammanabrolu et al.(2019))이 제안 되었음
        - 첫번째로 입력 스토리에서 이벤트를 추출해야 함
        - 다음 단계는 이 사건들을 이야기로 확장하는 것임
      - 우리는 검색 및 편집 방법(하시모토 외, 2018), 템플릿 채우기 방법, 시퀀스 투 시퀀스 방법의 강도를 각각 유한 상태 기계 디코더, 몬테 카를로 빔 디코딩, 바닐라 빔 디코딩과 결합하는 것으로 보고된 암마나브롤루 외(2019)에 의한 앙상블 모델을 실험
        - 이 방법은 출력 스토리를 생성하기 전 더 많은 이벤트를 포함하기 위해 이벤트 대 이벤트 생성을 먼저 수행함
        - 아래 그림 1은 어떻게 작동하는지 표현되어 있음   
        ![image](https://user-images.githubusercontent.com/49019292/209498055-7ee7836a-247c-4f0c-b183-b3b71b61774b.png)  
      - 추출된 엔티티 또는 관계가 target 스타일 말뭉치에서 대상 밖의 말뭉치 어휘라는 것에 주목할 필요
        - 예를 들어, 해리포터 코퍼스에는 컴퓨터라는 단어는 없음
      - 이 단어들을 target 말뭉치에서 훈련된 단어 임베딩까지 가장 가까운 언어 부분을 가진 단어로 대체할 필요가 있음
        - 거리 계산은 유클리드 거리 사용
    - Graph-based Method
      - 이 방법에서, story-realization 방법과 다른 말뭉치 어휘의 대체 체계가 입력 스토리에 사용되어 함
      - 데이터 세트에 대해 훈련된 그래프 변환기 및 기타 그래프 텍스트 생성기로 실험하고, 작업에 대한 성능을 비교하고, 수정을 통해 성능을 개선할 수 있는 가능성을 검토할 계획
      - GCN 기반 SOTA 엔티티 및 관계 추출 모델인 GraphRel을 사용하여 입력 스토리를 그래프로 변환하는 것으로 시작할 계획
      - 아래 그림 3은 그래프 기반 방법의 작동 방식을 보여줌   
      ![image](https://user-images.githubusercontent.com/49019292/209498069-16243639-f509-4879-8d81-680f6d3ce6b7.png) 
  - Evaluation
    - 이 작업의 창조적 특성을 고려하여 후자에 중점을 두고 perplexity과 인간 평가를 사용하여 생성한 이야기를 평가할 계획
    - 생성된 이야기는 문법과 유창성, 주요 줄거리 보존, 대상 스타일의 강도, 창의성 등의 측면에서 언어학자들에 의해 평가
    - 1과 5 사이의 점수가 부여되며, 1은 전체 실패를, 2는 거의 허용되지 않는 것을, 3은 허용 가능한 것을, 4는 양호한 것을, 5는 가장 만족스러운 성과를 나타냄
 -----------------------------------------------------
- **고찰**
  - 모델을 앙상블 하는 것도 꽤 괜찮은 contribution이 될 수 있다는 것을 알게 되었다.
  - 이 논문은 여러 방법을 실험한 것에 의의가 있는 듯
  - 총 세 가지 방법을 제시했는데, 그 중 그래프 기반 방법을 도입한 건 좀 색달랐다.
    - 지금까지 본 generation 논문에선 그래프 기반 방법을 적용시킨 건 없었던 것 같은데....
    - 근데 사실 여기서도 GCN은 계획만 써놓긴 했다.
    - 이래도 되는구나..
  - 여기 서도 평가는 인간 평가 방법을 채택했음
    - 확실히 create 하는 부분의 평가는 인간(전문가 그룹)이 하는 것이 가장 정확하다고 생각된다.
    - 뭔가 다른 평가 방법은 없을까..
